chebyshev inequality (we choose a rv/estimate $X$ such that we know how to compute $E(X)$ and Var(X), and then chebyshev???

what is the traingular ienquality for P and should we use it here?
??? P(|X-a| > k) \leq P(|X-b| > k/2) + P(|b-a| > k/2)????


P4

chebyshev inequality (we choose a rv/estimate $X$ such that we know how to compute $E(X)$ and Var(X), and then chebyshev???

what is the traingular ienquality for P and should we use it here?
??? P(|X-a| > k) \leq P(|X-b| > k/2) + P(|b-a| > k/2)????


----------

	if A \susbeteq B \cup C (which can be proven through triangular inequality, then P(A) \leq P(B \cup C) \leq P(B)+P(C)
-------------
q
By Chebyshev, we have $P(|X_n - E(X_n)| > \epsilon) < Var(X_n) 


lim P(|X_n-\mu|>\epsilon)=0

for any $\epsilon$
there exists N_1 s.t. $|E(X_n) - \mu| < \epsilon/2$
Hence by chebyshev P(|X_n - E(X_n)| > \epsilon/2)





\section*{no Mem}
listed vocab only? only start collecting sentence pattern when all vocab grabbed and understood?
at execution level, pure is faster?

いつ
出ました
使って
持って
同じ

誰か
言った
高い

なりました
聞いています

msd
already; so what?
熱い
どうぞ
言葉
顔

一つ

smarter index than s&p 500?
ar depend on chain of self, with one error term
arma depend on chain of self and chain of error term
arch error term has variance modelled by ar, white noise base
garch error term has variance modelled by arma, white noise base

ar: chain of prev input and current error
ma: current error = chain of prev error
arma: chain of prev input and chain of prev error (substitute ma in)
arch (error variance): chain of prev error
garch (error variance): chain of prev error and chain of prev variance


\section*{end}
v. ました/ます/ません
v. たい
adj. です/だ
n. が adj. (use adj to describe n.)
n. を quantity
surject は
object に/を verb


\section*{temp}
面白かった
すごく
明日
旅行し
お客様
日
旅行
思い
したらいい
言葉
分かりません
意味
気を付けてください
拭き
顔
長い
